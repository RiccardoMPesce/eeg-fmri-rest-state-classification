{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiccardoMPesce/eeg-fmri-rest-state-classification/blob/main/CNNForfMRIRestState.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "20ZhfEMr5JRZ"
      },
      "outputs": [],
      "source": [
        "import nibabel\n",
        "import mne\n",
        "\n",
        "import importlib\n",
        "import json\n",
        "import wandb\n",
        "\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from dataset_utils import *\n",
        "from dataset import *\n",
        "from train_utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DnXS9chVGcv7"
      },
      "outputs": [],
      "source": [
        "CWL_BASE_PATH = Path(\"CWLData\")\n",
        "MRI_BASE_PATH = CWL_BASE_PATH / \"mri\" / \"epi_normalized\"\n",
        "EEG_BASE_PATH = CWL_BASE_PATH / \"eeg\" / \"in-scan\"\n",
        "DATASET_BASE_PATH = CWL_BASE_PATH / \"dataset\"\n",
        "CHECKPOINT_PATH = CWL_BASE_PATH / \"checkpoints\"\n",
        "METRICS_PATH = CWL_BASE_PATH / \"metrics\"\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 10 ** (-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Backend options\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    print(\"CUDA available\")\n",
        "    mne.set_config(\"MNE_USE_CUDA\", \"True\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "    print(\"MPS (Metal) available\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"CPU available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tjFeCfqbaZGz"
      },
      "outputs": [],
      "source": [
        "DATASET_BASE_PATH.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wzv2QUcfaZGI"
      },
      "outputs": [],
      "source": [
        "mri_images = sorted([Path(image) for image in glob(str(MRI_BASE_PATH) + \"/*.nii\")])\n",
        "eeg_files = sorted([Path(eeg) for eeg in glob(str(EEG_BASE_PATH) + \"/*.set\") if \"mrcorrected\" not in eeg])\n",
        "eeg_files_mrcorrected = sorted([Path(eeg) for eeg in glob(str(EEG_BASE_PATH) + \"/*.set\") if \"mrcorrected\" in eeg])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ybrWM0UaUHzK"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yxKGRCbIDdp9"
      },
      "outputs": [],
      "source": [
        "dataset = EEGMRIDataset(DATASET_BASE_PATH / \"by_interval\", use_cwl=True)\n",
        "dataset_no_cwl = EEGMRIDataset(DATASET_BASE_PATH / \"by_interval\", use_cwl=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7ZJ7fzAED-nk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "class Splitter:\n",
        "    def __init__(self, dataset, split_dict, split_name):\n",
        "        # Set EEG dataset\n",
        "        self.dataset = dataset\n",
        "        # Load split\n",
        "        self.split_idx = split_dict[split_name]\n",
        "        # Compute size\n",
        "        self.size = len(self.split_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sample from dataset\n",
        "        eeg, fmri, label = self.dataset[self.split_idx[idx]]\n",
        "        # Return\n",
        "        return eeg, fmri, label\n",
        "\n",
        "\n",
        "def make_splits(dataset, train_frac=0.9, val_frac=0.05, test_frac=0.05):\n",
        "    splits = {}\n",
        "    \n",
        "    if train_frac + val_frac + test_frac != 1:\n",
        "        train_frac, val_frac, test_frac = 0.9, 0.05, 0.05\n",
        "\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        if split == \"train\":\n",
        "            frac = train_frac \n",
        "        elif split == \"val\":\n",
        "            frac = val_frac\n",
        "        else:\n",
        "            frac = test_frac \n",
        "\n",
        "        splits[split] = [indices.pop() for _ in range(int(round(len(dataset) * frac)))]\n",
        "    \n",
        "    return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7NocE3Tffegn"
      },
      "outputs": [],
      "source": [
        "splits = make_splits(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FlyEVSOWvvxL"
      },
      "outputs": [],
      "source": [
        "loaders = {split: DataLoader(Splitter(dataset, split_dict = splits, split_name = split), batch_size = BATCH_SIZE, drop_last = True, shuffle = True) for split in [\"train\", \"val\", \"test\"]}\n",
        "loaders_no_cwl = {split: DataLoader(Splitter(dataset_no_cwl, split_dict = splits, split_name = split), batch_size = BATCH_SIZE, drop_last = True, shuffle = True) for split in [\"train\", \"val\", \"test\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JHdGBFTzB820"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim, functional\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class ConvNet1D(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(input_channels, 32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.MaxPool1d(5))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv1d(32, 64, kernel_size=3, dilation=2),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.MaxPool1d(10))\n",
        "        self.layer3 = nn.Flatten()\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(2496, 512),\n",
        "            nn.Linear(512, 2),\n",
        "            nn.Softmax())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vxX38hTxPthR"
      },
      "outputs": [],
      "source": [
        "model_conv1d = ConvNet1D(38)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eYJ81fiXw4o3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def find_last_version(checkpoint_path):\n",
        "    logs_path = checkpoint_path / \"lightning_logs\"\n",
        "    versions = [p for p in logs_path.glob(\"*\") if (p / \"checkpoints\").exists()]\n",
        "    return logs_path / sorted(versions)[-1] if versions != [] else logs_path / \"\"\n",
        "\n",
        "def find_last_checkpoint(checkpoint_path):\n",
        "    checkpoints_path = find_last_version(checkpoint_path) / \"checkpoints\"\n",
        "    print(checkpoints_path)\n",
        "    if list(checkpoints_path.glob(\"*\")) == []:\n",
        "        return None\n",
        "    else:\n",
        "        last_checkpoint = list(checkpoints_path.glob(\"*\"))[0]\n",
        "    return checkpoints_path / last_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R87vgcj6EWsE",
        "outputId": "443c8cd6-4d68-4a01-d9bb-bb56117462a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded accuracy dictionary at /content/drive/MyDrive/CWLData/metrics/conv1d_accuracies.json\n",
            "Loaded loss dictionary at /content/drive/MyDrive/CWLData/metrics/conv1d_loss.json\n",
            "Loaded weights generated at epoch 46\n",
            "Training starting at epoch 47\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO\n",
            "- Model: ConvNet1D - epoch 47\n",
            "STATS\n",
            "- Training: Loss 0.6887, Accuracy 0.5492 - Validation: Loss 0.7057, Accuracy 0.3750 - Test: Loss 0.6866, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.3750) is 0.5833 at epoch 47\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 48\n",
            "STATS\n",
            "- Training: Loss 0.6878, Accuracy 0.5530 - Validation: Loss 0.7055, Accuracy 0.3750 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.3750) is 0.5417 at epoch 48\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 49\n",
            "STATS\n",
            "- Training: Loss 0.6879, Accuracy 0.5530 - Validation: Loss 0.7017, Accuracy 0.3958 - Test: Loss 0.6892, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.3958) is 0.5625 at epoch 49\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 50\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7023, Accuracy 0.4167 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5208 at epoch 50\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 51\n",
            "STATS\n",
            "- Training: Loss 0.6875, Accuracy 0.5540 - Validation: Loss 0.7071, Accuracy 0.3542 - Test: Loss 0.6905, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5208 at epoch 50\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 52\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5502 - Validation: Loss 0.7018, Accuracy 0.4167 - Test: Loss 0.6942, Accuracy 0.5000\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 52\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 53\n",
            "STATS\n",
            "- Training: Loss 0.6889, Accuracy 0.5502 - Validation: Loss 0.7016, Accuracy 0.4167 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 54\n",
            "STATS\n",
            "- Training: Loss 0.6878, Accuracy 0.5530 - Validation: Loss 0.7101, Accuracy 0.3333 - Test: Loss 0.6903, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 55\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5511 - Validation: Loss 0.7038, Accuracy 0.3958 - Test: Loss 0.6885, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 56\n",
            "STATS\n",
            "- Training: Loss 0.6886, Accuracy 0.5502 - Validation: Loss 0.7029, Accuracy 0.3958 - Test: Loss 0.6905, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 57\n",
            "STATS\n",
            "- Training: Loss 0.6886, Accuracy 0.5502 - Validation: Loss 0.7069, Accuracy 0.3750 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 58\n",
            "STATS\n",
            "- Training: Loss 0.6875, Accuracy 0.5540 - Validation: Loss 0.7023, Accuracy 0.4167 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5625 at epoch 58\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 59\n",
            "STATS\n",
            "- Training: Loss 0.6883, Accuracy 0.5511 - Validation: Loss 0.7037, Accuracy 0.3958 - Test: Loss 0.6942, Accuracy 0.5000\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5625 at epoch 58\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 60\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7015, Accuracy 0.4167 - Test: Loss 0.6868, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5833 at epoch 60\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 61\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5530 - Validation: Loss 0.7059, Accuracy 0.3750 - Test: Loss 0.6865, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5833 at epoch 60\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 62\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.7020, Accuracy 0.4167 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 62\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 63\n",
            "STATS\n",
            "- Training: Loss 0.6877, Accuracy 0.5530 - Validation: Loss 0.7043, Accuracy 0.3958 - Test: Loss 0.6903, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 62\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 64\n",
            "STATS\n",
            "- Training: Loss 0.6884, Accuracy 0.5502 - Validation: Loss 0.7094, Accuracy 0.3333 - Test: Loss 0.6961, Accuracy 0.4792\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 62\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 65\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.7015, Accuracy 0.4167 - Test: Loss 0.6941, Accuracy 0.5000\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 66\n",
            "STATS\n",
            "- Training: Loss 0.6876, Accuracy 0.5540 - Validation: Loss 0.7030, Accuracy 0.3958 - Test: Loss 0.6869, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 67\n",
            "STATS\n",
            "- Training: Loss 0.6885, Accuracy 0.5511 - Validation: Loss 0.7115, Accuracy 0.3333 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 68\n",
            "STATS\n",
            "- Training: Loss 0.6877, Accuracy 0.5540 - Validation: Loss 0.7043, Accuracy 0.3958 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 69\n",
            "STATS\n",
            "- Training: Loss 0.6879, Accuracy 0.5530 - Validation: Loss 0.7041, Accuracy 0.3958 - Test: Loss 0.6903, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 70\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5521 - Validation: Loss 0.7030, Accuracy 0.3958 - Test: Loss 0.6905, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 71\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5521 - Validation: Loss 0.7088, Accuracy 0.3542 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 72\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.6978, Accuracy 0.4583 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 73\n",
            "STATS\n",
            "- Training: Loss 0.6883, Accuracy 0.5511 - Validation: Loss 0.7064, Accuracy 0.3542 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 74\n",
            "STATS\n",
            "- Training: Loss 0.6883, Accuracy 0.5511 - Validation: Loss 0.7082, Accuracy 0.3542 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 75\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5502 - Validation: Loss 0.7017, Accuracy 0.4167 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 76\n",
            "STATS\n",
            "- Training: Loss 0.6886, Accuracy 0.5483 - Validation: Loss 0.7052, Accuracy 0.3750 - Test: Loss 0.6867, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 77\n",
            "STATS\n",
            "- Training: Loss 0.6884, Accuracy 0.5502 - Validation: Loss 0.7079, Accuracy 0.3542 - Test: Loss 0.6884, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 78\n",
            "STATS\n",
            "- Training: Loss 0.6887, Accuracy 0.5492 - Validation: Loss 0.7064, Accuracy 0.3750 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 79\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7047, Accuracy 0.3750 - Test: Loss 0.6905, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 80\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5521 - Validation: Loss 0.7069, Accuracy 0.3750 - Test: Loss 0.6986, Accuracy 0.4583\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 81\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7028, Accuracy 0.3958 - Test: Loss 0.6958, Accuracy 0.4792\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 82\n",
            "STATS\n",
            "- Training: Loss 0.6884, Accuracy 0.5502 - Validation: Loss 0.7019, Accuracy 0.4167 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 83\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7042, Accuracy 0.3958 - Test: Loss 0.6903, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 84\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5511 - Validation: Loss 0.7077, Accuracy 0.3542 - Test: Loss 0.6885, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 85\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5521 - Validation: Loss 0.7022, Accuracy 0.4167 - Test: Loss 0.6844, Accuracy 0.6042\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 86\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.7055, Accuracy 0.3750 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 87\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7090, Accuracy 0.3333 - Test: Loss 0.6886, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 88\n",
            "STATS\n",
            "- Training: Loss 0.6885, Accuracy 0.5502 - Validation: Loss 0.7077, Accuracy 0.3542 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 89\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5511 - Validation: Loss 0.7016, Accuracy 0.4167 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 90\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5511 - Validation: Loss 0.7023, Accuracy 0.4167 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 91\n",
            "STATS\n",
            "- Training: Loss 0.6885, Accuracy 0.5502 - Validation: Loss 0.7041, Accuracy 0.3958 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 92\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.7029, Accuracy 0.3958 - Test: Loss 0.6887, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 93\n",
            "STATS\n",
            "- Training: Loss 0.6877, Accuracy 0.5540 - Validation: Loss 0.7018, Accuracy 0.4167 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 94\n",
            "STATS\n",
            "- Training: Loss 0.6879, Accuracy 0.5521 - Validation: Loss 0.7058, Accuracy 0.3750 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 95\n",
            "STATS\n",
            "- Training: Loss 0.6879, Accuracy 0.5521 - Validation: Loss 0.7054, Accuracy 0.3750 - Test: Loss 0.6885, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 96\n",
            "STATS\n",
            "- Training: Loss 0.6884, Accuracy 0.5492 - Validation: Loss 0.7022, Accuracy 0.4167 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 97\n",
            "STATS\n",
            "- Training: Loss 0.6876, Accuracy 0.5540 - Validation: Loss 0.7069, Accuracy 0.3750 - Test: Loss 0.6881, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 98\n",
            "STATS\n",
            "- Training: Loss 0.6876, Accuracy 0.5530 - Validation: Loss 0.7017, Accuracy 0.4167 - Test: Loss 0.6866, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n"
          ]
        }
      ],
      "source": [
        "conv1d_optimizer = torch.optim.Adam(model_conv1d.parameters(), lr=LEARNING_RATE)\n",
        "train_loop(model_conv1d, loaders, conv1d_optimizer, METRICS_PATH / \"conv1d_accuracies.json\", METRICS_PATH / \"conv1d_loss.json\", CHECKPOINT_PATH / \"conv1d_checkpoints\", 52)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "AckwvVkCKPIs",
        "outputId": "bb1c9e21-1458-410a-f2ba-29325314fbcd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fc502fb2fd29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_conv1d_no_cwl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv1d_no_cwl_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv1d_no_cwl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv1d_no_cwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_no_cwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_no_cwl_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETRICS_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"conv1d_no_cwl_accuracies.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETRICS_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"conv1d_no_cwl_loss.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"conv1d_no_cwl_checkpoints\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ConvNet1D' is not defined"
          ]
        }
      ],
      "source": [
        "model_conv1d_no_cwl = ConvNet1D(32)\n",
        "conv1d_no_cwl_optimizer = torch.optim.Adam(model_conv1d_no_cwl.parameters(), lr=LEARNING_RATE)\n",
        "train_loop(model_conv1d_no_cwl, loaders_no_cwl, conv1d_no_cwl_optimizer, METRICS_PATH / \"conv1d_no_cwl_accuracies.json\", METRICS_PATH / \"conv1d_no_cwl_loss.json\", CHECKPOINT_PATH / \"conv1d_no_cwl_checkpoints\", 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5UYnywgKSOH"
      },
      "outputs": [],
      "source": [
        "class ConvNet3D(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv3d(input_channels, 32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.MaxPool1d(5))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv3d(32, 64, kernel_size=3, dilation=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.MaxPool1d(10))\n",
        "        self.layer3 = nn.Flatten()\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(2496,2),\n",
        "            nn.Softmax())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KrqCMH1WR6N"
      },
      "outputs": [],
      "source": [
        "def train_loop_fmri(model, loaders, optimizer, accuracy_json, loss_json, checkpoint_prefix, n_epochs, debug=False, save_every=2):\n",
        "    # Initialize training, validation, test losses and accuracy list\n",
        "\n",
        "    accuracy_json_file_path = Path(accuracy_json)\n",
        "    loss_json_file_path = Path(loss_json)\n",
        "\n",
        "    if accuracy_json_file_path.exists() and accuracy_json_file_path.is_file():\n",
        "        with open(accuracy_json_file_path, \"r+\") as accuracy_json_f:\n",
        "            accuracies_per_epoch = json.load(accuracy_json_f)\n",
        "            print(f\"Loaded accuracy dictionary at {accuracy_json_file_path}\")\n",
        "    else:\n",
        "        accuracies_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "    if loss_json_file_path.exists() and loss_json_file_path.is_file():\n",
        "        with open(loss_json_file_path, \"r+\") as loss_json_f:\n",
        "            losses_per_epoch = json.load(loss_json_f)\n",
        "            print(f\"Loaded loss dictionary at {loss_json_file_path}\")\n",
        "    else:\n",
        "        losses_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "    starting_epoch = 0\n",
        "\n",
        "    checkpoint_path = Path(checkpoint_prefix) \n",
        "\n",
        "    checkpoint_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # Check for the latest weights\n",
        "    checkpoints = [checkpoint.name for checkpoint in checkpoint_path.glob(\"*.pth\") if checkpoint.is_file()]\n",
        "\n",
        "    if len(checkpoints) > 0:\n",
        "        epochs = [int(s.replace(\".pth\", \"\")) for s in checkpoints]\n",
        "\n",
        "        latest_state_dict_path = checkpoint_path / f\"{max(epochs)}.pth\"\n",
        "\n",
        "        # Loading state dict\n",
        "        model.load_state_dict(torch.load(latest_state_dict_path, map_location=DEVICE))\n",
        "        print(f\"Loaded weights generated at epoch {max(epochs)}\")\n",
        "\n",
        "        starting_epoch = max(epochs)\n",
        "\n",
        "    best_accuracy = 0\n",
        "    best_accuracy_val = 0\n",
        "    best_epoch = 0\n",
        "    \n",
        "    predicted_labels = [] \n",
        "    correct_labels = []\n",
        "\n",
        "    print(f\"Training starting at epoch {starting_epoch + 1}\")\n",
        "    for epoch in range(starting_epoch + 1, n_epochs + starting_epoch + 1):\n",
        "        # Initialize loss/accuracy variables\n",
        "        losses = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        accuracies = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        \n",
        "        # Adjust learning rate for SGD\n",
        "        \"\"\"\n",
        "        if OPTIMIZER == \"SGD\":\n",
        "            lr = LEARNING_RATE * (LR_DECAY ** (epoch // LEARNING_RATE_DECAY_EVERY))\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group[\"lr\"] = lr\n",
        "        \"\"\"\n",
        "        \n",
        "        # Process each split\n",
        "        for split in (\"train\", \"val\", \"test\"):\n",
        "            # Set network mode\n",
        "            if split == \"train\":\n",
        "                model.train()\n",
        "                torch.set_grad_enabled(True)\n",
        "            else:\n",
        "                model.eval()\n",
        "                torch.set_grad_enabled(False)\n",
        "            \n",
        "            # Process all split batches\n",
        "            for i, (_, input, target) in enumerate(loaders[split]):\n",
        "\n",
        "                # Move model to device\n",
        "                model = model.to(DEVICE)\n",
        "                \n",
        "                # Move tensors to device\n",
        "                input = input.to(DEVICE)\n",
        "                target = target.to(DEVICE)\n",
        "                \n",
        "                if debug:\n",
        "                    print(input.device)\n",
        "\n",
        "                # Forward\n",
        "                output = model(input.squeeze())\n",
        "\n",
        "                # Compute loss\n",
        "                loss = F.cross_entropy(output, target)\n",
        "                losses[split] += loss.item()\n",
        "                \n",
        "                # Compute accuracy\n",
        "                _, pred = output.data.max(1)\n",
        "                correct = pred.eq(target.data).sum().item()\n",
        "                accuracy = correct / input.data.size(0)   \n",
        "                accuracies[split] += accuracy\n",
        "                counts[split] += 1\n",
        "                \n",
        "                # Backward and optimize\n",
        "                if split == \"train\":\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "        \n",
        "        # Print info at the end of the epoch\n",
        "        if accuracies[\"val\"] / counts[\"val\"] >= best_accuracy_val:\n",
        "            best_accuracy_val = accuracies[\"val\"] / counts[\"val\"]\n",
        "            best_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
        "            best_epoch = epoch\n",
        "\n",
        "        train_loss = losses[\"train\"] / counts[\"train\"]\n",
        "        train_accuracy = accuracies[\"train\"] / counts[\"train\"]\n",
        "        validation_loss = losses[\"val\"] / counts[\"val\"]\n",
        "        validation_accuracy = accuracies[\"val\"] / counts[\"val\"]\n",
        "        test_loss = losses[\"test\"] / counts[\"test\"]\n",
        "        test_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
        "\n",
        "        print(\"INFO\")\n",
        "        print(f\"- Model: {model.__class__.__name__}\")\n",
        "        print(\"STATS\")\n",
        "        print(f\"- Training: Loss {train_loss:.4f}, Accuracy {train_accuracy:.4f} \" \n",
        "            f\"- Validation: Loss {validation_loss:.4f}, Accuracy {validation_accuracy:.4f} \"\n",
        "            f\"- Test: Loss {test_loss:.4f}, Accuracy {test_accuracy:.4f}\")\n",
        "        print(f\"Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = {best_accuracy_val:.4f}) is {best_accuracy:.4f} at epoch {best_epoch}\\n\")\n",
        "\n",
        "        losses_per_epoch[\"train\"].append(train_loss)\n",
        "        losses_per_epoch[\"val\"].append(validation_loss)\n",
        "        losses_per_epoch[\"test\"].append(test_loss)\n",
        "        accuracies_per_epoch[\"train\"].append(train_accuracy)\n",
        "        accuracies_per_epoch[\"val\"].append(validation_accuracy)\n",
        "        accuracies_per_epoch[\"test\"].append(test_accuracy)\n",
        "\n",
        "        if epoch % save_every == 0:\n",
        "            torch.save(model.state_dict(), checkpoint_path / f\"{epoch}.pth\")\n",
        "            \n",
        "            with open(accuracy_json_file_path, \"w+\") as accuracy_json_f:\n",
        "                json.dump(accuracies_per_epoch, accuracy_json_f)\n",
        "            \n",
        "            with open(loss_json_file_path, \"w+\") as loss_json_f:\n",
        "                json.dump(losses_per_epoch, loss_json_f)\n",
        "\n",
        "    # At the end of training, save\n",
        "    torch.save(model.state_dict(), checkpoint_path / f\"{epoch}.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yxCphOeUIgCe",
        "outputId": "4fbb4d64-6090-4051-d45c-9bfb9905d3d8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ConvNet1D'"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_conv3d = ConvNet3D(1)\n",
        "conv3d_optimizer = torch.optim.Adam(model_conv3d.parameters(), lr=LEARNING_RATE)\n",
        "train_loop_fmri(model_conv3d, loaders, conv3d_optimizer, METRICS_PATH / \"conv3d_accuracies.json\", METRICS_PATH / \"conv3d_loss.json\", CHECKPOINT_PATH / \"conv3d_checkpoints\", 100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "095fuS9UQBCE"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyPy0CAMvCsVa5T9CapVtXZT",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
