{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RiccardoMPesce/eeg-fmri-rest-state-classification/blob/main/CNNForfMRIRestState.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6A9YqbW1OiF",
        "outputId": "d7624b36-e304-47c3-d1be-e19ce7d149de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nibabel in /usr/local/lib/python3.9/dist-packages (3.0.2)\n",
            "Collecting mne\n",
            "  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nilearn\n",
            "  Downloading nilearn-0.10.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.9/dist-packages (from nibabel) (1.22.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from mne) (4.65.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mne) (23.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from mne) (3.5.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from mne) (1.10.1)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.9/dist-packages (from mne) (1.7.0)\n",
            "Collecting nibabel\n",
            "  Downloading nibabel-5.0.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from nilearn) (1.1.1)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from nilearn) (1.4.4)\n",
            "Requirement already satisfied: requests>=2.25.0 in /usr/local/lib/python3.9/dist-packages (from nilearn) (2.25.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from nilearn) (1.2.2)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nilearn) (4.9.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from nibabel) (63.4.3)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->nilearn) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->nilearn) (2.8.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne) (3.1.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.25.0->nilearn) (1.26.15)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.25.0->nilearn) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.25.0->nilearn) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.25.0->nilearn) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->nilearn) (3.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->mne) (2.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (4.39.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->mne) (1.4.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.1.5->nilearn) (1.15.0)\n",
            "Installing collected packages: nibabel, nilearn, mne\n",
            "  Attempting uninstall: nibabel\n",
            "    Found existing installation: nibabel 3.0.2\n",
            "    Uninstalling nibabel-3.0.2:\n",
            "      Successfully uninstalled nibabel-3.0.2\n",
            "Successfully installed mne-1.3.1 nibabel-5.0.1 nilearn-0.10.0\n"
          ]
        }
      ],
      "source": [
        "! pip install nibabel mne nilearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r02D2v753ac7",
        "outputId": "805cd4f1-d7a5-4ab9-9286-7c01ebaa711f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "20ZhfEMr5JRZ"
      },
      "outputs": [],
      "source": [
        "import nibabel\n",
        "import mne\n",
        "\n",
        "import importlib\n",
        "\n",
        "from fastai.vision.all import *\n",
        "\n",
        "from glob import glob\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DnXS9chVGcv7"
      },
      "outputs": [],
      "source": [
        "def extract_relevant_markers_from_eeg(eeg_file, kind):\n",
        "    recording_metadata = list(zip(eeg_file.annotations.description.tolist(), eeg_file.annotations.onset.tolist()))\n",
        "    clean_recs_markers = [(rec[0], int(rec[1] * 1000)) for rec in recording_metadata if rec[0] in (\"eeo\", \"eec\", \"beo\", \"bec\", \"mri\")]\n",
        "    \n",
        "    clean_markers = clean_recs_markers[:]\n",
        "\n",
        "    t_r = 1.95 if kind == \"trio\" else 2.00\n",
        "\n",
        "    mri_intervals = []\n",
        "\n",
        "    last_annotation = None\n",
        "\n",
        "    for (a, t) in clean_markers:\n",
        "        if a in (\"beo\", \"eeo\", \"bec\", \"eec\"):\n",
        "            last_annotation = a\n",
        "        else:\n",
        "            if last_annotation == \"beo\" and a == \"mri\":\n",
        "                mri_intervals += [((t, t + int(t_r * 1000)), \"eo\")]\n",
        "            elif last_annotation == \"bec\" and a == \"mri\":\n",
        "                mri_intervals += [((t, t + int(t_r * 1000)), \"ec\")]\n",
        "            else:\n",
        "                pass\n",
        "    \n",
        "    return mri_intervals\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "epj7yhBmJRxQ"
      },
      "outputs": [],
      "source": [
        "def retrive_times_fmri_cwl(raw):\n",
        "    \"\"\"\n",
        "    Extract information from annottation raw file about fmri frames.\n",
        "    This information importatn for further interpo\n",
        "    \n",
        "    -----\n",
        "    Input\n",
        "    Raw is file from EEG set.\n",
        "    Retrive fMRI time annotation. When occurs recordings in seconds\n",
        "    It is useful for aligning EEG and fMRI data \n",
        "    \n",
        "    Output: \n",
        "    times_fmri - np \n",
        "        array of times in ms .\n",
        "    \"\"\"\n",
        "    \n",
        "    times_fmri = []\n",
        "    for annot in raw.annotations:\n",
        "        if annot['description'] == \"mri\":\n",
        "            times_fmri.append(annot['onset'])\n",
        "\n",
        "    times_fmri = np.array(times_fmri)\n",
        "    times_fmri = times_fmri * 1000  # seconds to milliseconds\n",
        "    \n",
        "    return times_fmri"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VosHZUe0KxuY"
      },
      "source": [
        "Actual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "S4QLi5z_aZJE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9f966c7-ccf3-48ed-abc4-71bb5e871ca0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU available\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from glob import glob\n",
        "\n",
        "import json\n",
        "\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "CWL_BASE_PATH = Path(\"/content/drive/MyDrive/CWLData/\")\n",
        "MRI_BASE_PATH = CWL_BASE_PATH / \"mri\" / \"epi_normalized\"\n",
        "EEG_BASE_PATH = CWL_BASE_PATH / \"eeg\" / \"in-scan\"\n",
        "DATASET_BASE_PATH = CWL_BASE_PATH / \"dataset\"\n",
        "CHECKPOINT_PATH = CWL_BASE_PATH / \"checkpoints\"\n",
        "METRICS_PATH = CWL_BASE_PATH / \"metrics\"\n",
        "\n",
        "# Hyperparameters\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 10 ** (-4)\n",
        "\n",
        "# Backend options\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    print(\"CUDA available\")\n",
        "    mne.set_config(\"MNE_USE_CUDA\", \"True\")\n",
        "elif torch.backends.mps.is_available():\n",
        "    DEVICE = torch.device(\"mps\")\n",
        "    # BATCH_SIZE = 440\n",
        "    print(\"MPS (Metal) available\")\n",
        "else:\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "    print(\"CPU available\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "tjFeCfqbaZGz"
      },
      "outputs": [],
      "source": [
        "DATASET_BASE_PATH.mkdir(exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wzv2QUcfaZGI"
      },
      "outputs": [],
      "source": [
        "mri_images = sorted([Path(image) for image in glob(str(MRI_BASE_PATH) + \"/*.nii\")])\n",
        "eeg_files = sorted([Path(eeg) for eeg in glob(str(EEG_BASE_PATH) + \"/*.set\") if \"mrcorrected\" not in eeg])\n",
        "eeg_files_mrcorrected = sorted([Path(eeg) for eeg in glob(str(EEG_BASE_PATH) + \"/*.set\") if \"mrcorrected\" in eeg])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Mz7u6R6_QnjT"
      },
      "outputs": [],
      "source": [
        "def dump_dataset_to_json(mri_images, eeg_files):\n",
        "    couples = zip(mri_images, eeg_files)\n",
        "\n",
        "    for mri_file, eeg_file in couples:\n",
        "        eeg = mne.io.read_raw_eeglab(eeg_file)\n",
        "        mri = nibabel.load(mri_file)\n",
        "\n",
        "        filename = eeg_file.name.replace(\".set\", \"\")\n",
        "        kind = \"trio\" if \"trio\" in filename else \"verio\"\n",
        "\n",
        "        intervals = extract_relevant_markers_from_eeg(eeg, kind=kind)\n",
        "\n",
        "        chunk_size = min(len(intervals), mri.get_fdata().shape[-1])\n",
        "\n",
        "        ds = {\n",
        "            \"eeg\": [],\n",
        "            \"fmri\": [],\n",
        "            \"label\": []\n",
        "        }\n",
        "\n",
        "        ds_no_cwl = {\n",
        "            \"eeg\": [],\n",
        "            \"fmri\": [],\n",
        "            \"label\": []\n",
        "        }\n",
        "\n",
        "        print(f\"Shape of data: {eeg.get_data().shape}\")\n",
        "\n",
        "        eeg_data = eeg.get_data()\n",
        "        eeg_data_no_cwl = eeg.get_data(picks=[ch for ch in eeg.ch_names if \"cw\" not in ch.lower()])\n",
        "        mri_data = mri.get_fdata()\n",
        "        fmri_data = list(a.tolist() for a in np.array_split(mri_data, mri_data.shape[-1], axis=3))\n",
        "\n",
        "        for (start, end), label in (intervals if len(intervals) <= chunk_size else intervals[:chunk_size]):\n",
        "            eeg_chunk = eeg_data[:, start:end].tolist()\n",
        "            eeg_chunk_no_cwl = eeg_data_no_cwl[:, start:end].tolist()\n",
        "\n",
        "            ds[\"label\"] += [label]\n",
        "            ds_no_cwl[\"label\"] += [label]\n",
        "\n",
        "            ds[\"eeg\"] += [eeg_chunk]\n",
        "            ds_no_cwl[\"eeg\"] += [eeg_chunk_no_cwl]\n",
        "\n",
        "        ds[\"fmri\"] = fmri_data if len(fmri_data) < chunk_size else fmri_data[:chunk_size]\n",
        "        ds_no_cwl[\"fmri\"] = fmri_data if len(fmri_data) < chunk_size else fmri_data[:chunk_size]\n",
        "\n",
        "        ds_file = DATASET_BASE_PATH / (filename + \"_dataset.json\")\n",
        "        ds_file_no_cwl = DATASET_BASE_PATH / (filename + \"_no_cwl_dataset.json\")\n",
        "\n",
        "        with open(ds_file, \"w\") as ds_file:\n",
        "            json.dump(ds, ds_file)\n",
        "\n",
        "        with open(ds_file_no_cwl, \"w\") as ds_file_no_cwl:\n",
        "            json.dump(ds_no_cwl, ds_file_no_cwl)\n",
        "\n",
        "        print(\"Dumped \", filename)\n",
        "        \n",
        "        eeg_data = None\n",
        "        \n",
        "        eeg = None\n",
        "        mri = None\n",
        "        ds = {}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DnJaMywK6F3f"
      },
      "outputs": [],
      "source": [
        "def melt_json(folder_path, out_file_name, use_cwl=True, dump_every=2):\n",
        "    melted = []\n",
        "\n",
        "    files = [f for f in Path(folder_path).glob(\"*dataset*\") if \"no_cwl\" not in f.name] if use_cwl else [f for f in Path(folder_path).glob(\"*dataset*\") if \"no_cwl\" in f.name]\n",
        "    \n",
        "    Path(out_file_name).touch(exist_ok=True)\n",
        "\n",
        "    for count_processed, f in enumerate(files):\n",
        "        print(f\"Processing {f.name}\")\n",
        "\n",
        "        with open(f, \"r\") as in_f:\n",
        "            ds = json.load(in_f)\n",
        "\n",
        "        with open(out_file_name, \"w\") as out_f:\n",
        "            keys = list(ds.keys())\n",
        "\n",
        "            size = len(keys)\n",
        "\n",
        "            for i in range(size):\n",
        "                for key in keys:\n",
        "                    melted = [{\n",
        "                        key: ds[key][i]\n",
        "                    }]\n",
        "\n",
        "            if count_processed % dump_every == 0:\n",
        "                json.dump(melted, out_f)\n",
        "\n",
        "    return len(melted)\n",
        "        \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "eFRXD4QGAnG5"
      },
      "outputs": [],
      "source": [
        "# melt_json(DATASET_BASE_PATH, DATASET_BASE_PATH / \"melted_ds.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "i_hR0xAQAx8_"
      },
      "outputs": [],
      "source": [
        "def dump_json_by_step(mri_files, eeg_files):\n",
        "    ds = []\n",
        "    ds_no_cwl = []\n",
        "    couples = zip(mri_images, eeg_files)\n",
        "    \n",
        "    for mri_file, eeg_file in couples:\n",
        "        eeg = mne.io.read_raw_eeglab(eeg_file)\n",
        "        mri = nibabel.load(mri_file)\n",
        "\n",
        "        filename = eeg_file.name.replace(\".set\", \"\")\n",
        "        kind = \"trio\" if \"trio\" in filename else \"verio\"\n",
        "\n",
        "        intervals = extract_relevant_markers_from_eeg(eeg, kind=kind)\n",
        "\n",
        "        chunk_size = min(len(intervals), mri.get_fdata().shape[-1])\n",
        "\n",
        "        print(f\"Shape of data: {eeg.get_data().shape}\")\n",
        "\n",
        "        eeg_data = eeg.get_data()\n",
        "        eeg_data_no_cwl = eeg.get_data(picks=[ch for ch in eeg.ch_names if \"cw\" not in ch.lower()])\n",
        "        mri_data = mri.get_fdata()\n",
        "        fmri_data = list(a.tolist() for a in np.array_split(mri_data, mri_data.shape[-1], axis=3))\n",
        "\n",
        "        entry = {}\n",
        "        entry_no_cwl = {}\n",
        "\n",
        "        for (start, end), label in (intervals if len(intervals) <= chunk_size else intervals[:chunk_size]):\n",
        "            eeg_chunk = eeg_data[:, start:end].tolist()\n",
        "            eeg_chunk_no_cwl = eeg_data_no_cwl[:, start:end].tolist()\n",
        "\n",
        "            entry[\"label\"] = label\n",
        "            entry_no_cwl[\"label\"] = label\n",
        "\n",
        "            entry[\"eeg\"] = eeg_chunk\n",
        "            entry_no_cwl[\"eeg\"] = eeg_chunk_no_cwl\n",
        "\n",
        "        entry[\"fmri\"] = fmri_data if len(fmri_data) < chunk_size else fmri_data[:chunk_size]\n",
        "        entry_no_cwl[\"fmri\"] = fmri_data if len(fmri_data) < chunk_size else fmri_data[:chunk_size]\n",
        "\n",
        "        ds_file = DATASET_BASE_PATH / \"dataset_melted.json\"\n",
        "        ds_file_no_cwl = DATASET_BASE_PATH / \"no_cwl_dataset_melted.json\"\n",
        "\n",
        "        ds += [entry]\n",
        "        ds_no_cwl += [entry_no_cwl]\n",
        "\n",
        "        with open(ds_file, \"w\") as ds_file:\n",
        "            json.dump(ds, ds_file)\n",
        "\n",
        "        with open(ds_file_no_cwl, \"w\") as ds_file_no_cwl:\n",
        "            json.dump(ds_no_cwl, ds_file_no_cwl)\n",
        "\n",
        "        print(\"Dumped \", filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-alrAc_c4Xh1"
      },
      "outputs": [],
      "source": [
        "def dump_dataset_by_interval(eeg_files, mri_files):\n",
        "    (DATASET_BASE_PATH / \"by_interval\").mkdir(exist_ok=True)\n",
        "\n",
        "    couples = zip(eeg_files, mri_files)\n",
        "\n",
        "    for mri_file, eeg_file in couples:\n",
        "        eeg = mne.io.read_raw_eeglab(eeg_file)\n",
        "        mri = nibabel.load(mri_file)\n",
        "\n",
        "        filename = eeg_file.name.replace(\".set\", \"\")\n",
        "        kind = \"trio\" if \"trio\" in filename else \"verio\"\n",
        "\n",
        "        intervals = extract_relevant_markers_from_eeg(eeg, kind=kind)\n",
        "\n",
        "        chunk_size = min(len(intervals), mri.get_fdata().shape[-1])\n",
        "\n",
        "        eeg_data = eeg.get_data()\n",
        "        eeg_data_no_cwl = eeg.get_data(picks=[ch for ch in eeg.ch_names if \"cw\" not in ch.lower()])\n",
        "        mri_data = mri.get_fdata()\n",
        "        fmri_data = list(a.tolist() for a in np.array_split(mri_data, mri_data.shape[-1], axis=3))\n",
        "\n",
        "        for i, ((start, end), label) in enumerate((intervals if len(intervals) <= chunk_size else intervals[:chunk_size])):\n",
        "            entry = {}\n",
        "            entry_no_cwl = {}\n",
        "\n",
        "            eeg_chunk = eeg_data[:, start:end].tolist()\n",
        "            eeg_chunk_no_cwl = eeg_data_no_cwl[:, start:end].tolist()\n",
        "\n",
        "            entry[\"label\"] = label\n",
        "            entry_no_cwl[\"label\"] = label\n",
        "\n",
        "            entry[\"eeg\"] = eeg_chunk\n",
        "            entry_no_cwl[\"eeg\"] = eeg_chunk_no_cwl\n",
        "\n",
        "            entry[\"fmri\"] = fmri_data[i] \n",
        "            entry_no_cwl[\"fmri\"] = fmri_data[i] \n",
        "\n",
        "            with open(DATASET_BASE_PATH / \"by_interval\" / f\"{filename}_s{start}_e{end}\", \"w\") as ds_file:\n",
        "                json.dump(entry, ds_file)\n",
        "\n",
        "            with open(DATASET_BASE_PATH / \"by_interval\" / f\"{filename}_no_cwl_s{start}_e{end}\", \"w\") as ds_file_no_cwl:\n",
        "                json.dump(entry_no_cwl, ds_file_no_cwl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIZDvNui8b_S",
        "outputId": "390fa095-9813-4b14-83dd-b5bc1dfce568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "print(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ybrWM0UaUHzK"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "class EEGMRIDataset(Dataset):\n",
        "    def __init__(self, directory_path, use_cwl=None, he_pump=None):\n",
        "        self.dataset_files = list(Path(directory_path).glob(\"*\"))\n",
        "\n",
        "        self.use_cwl = use_cwl\n",
        "        \n",
        "        if use_cwl is not None:\n",
        "            if use_cwl:\n",
        "                self.dataset_files = [f for f in self.dataset_files if \"no_cwl\" not in f.name]\n",
        "            else:\n",
        "                self.dataset_files = [f for f in self.dataset_files if \"no_cwl\" in f.name]\n",
        "\n",
        "        if he_pump is not None:\n",
        "            if he_pump:\n",
        "                self.dataset_files = [f for f in self.dataset_files if \"hpump-on\" in f.name]\n",
        "            else:\n",
        "                self.dataset_files = [f for f in self.dataset_files if \"hpump-off\" in f.name]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset_files) \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        f_path = self.dataset_files[idx]\n",
        "        \n",
        "        with open(f_path, \"r\") as f_p:\n",
        "            observation = json.load(f_p)\n",
        "        \n",
        "        label = 1 if observation[\"label\"] == \"eo\" else 0\n",
        "        fmri = torch.Tensor(observation[\"fmri\"])\n",
        "        eeg = torch.Tensor(observation[\"eeg\"])\n",
        "\n",
        "        if eeg.shape[1] < 2000:\n",
        "            eeg = torch.cat((eeg, torch.zeros((eeg.shape[0], 50))), axis=1)\n",
        "\n",
        "        if eeg.shape[0] not in (32, 38):\n",
        "            if self.use_cwl:\n",
        "                eeg = torch.cat((eeg, torch.zeros((38 - eeg.shape[0], eeg.shape[1]))), axis=0)\n",
        "            else:\n",
        "                eeg = torch.cat((eeg, torch.zeros((32 - eeg.shape[0], eeg.shape[1]))), axis=0)\n",
        "\n",
        "        fmri = fmri.reshape(1, fmri.shape[0], fmri.shape[1], fmri.shape[2])\n",
        "\n",
        "        return eeg, fmri, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "yxKGRCbIDdp9"
      },
      "outputs": [],
      "source": [
        "dataset = EEGMRIDataset(DATASET_BASE_PATH / \"by_interval\", use_cwl=True)\n",
        "dataset_no_cwl = EEGMRIDataset(DATASET_BASE_PATH / \"by_interval\", use_cwl=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "7ZJ7fzAED-nk"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "class Splitter:\n",
        "    def __init__(self, dataset, split_dict, split_name):\n",
        "        # Set EEG dataset\n",
        "        self.dataset = dataset\n",
        "        # Load split\n",
        "        self.split_idx = split_dict[split_name]\n",
        "        # Compute size\n",
        "        self.size = len(self.split_idx)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Get sample from dataset\n",
        "        eeg, fmri, label = self.dataset[self.split_idx[idx]]\n",
        "        # Return\n",
        "        return eeg, fmri, label\n",
        "\n",
        "\n",
        "def make_splits(dataset, train_frac=0.9, val_frac=0.05, test_frac=0.05):\n",
        "    splits = {}\n",
        "    \n",
        "    if train_frac + val_frac + test_frac != 1:\n",
        "        train_frac, val_frac, test_frac = 0.9, 0.05, 0.05\n",
        "\n",
        "    indices = list(range(len(dataset)))\n",
        "\n",
        "    random.shuffle(indices)\n",
        "\n",
        "    for split in [\"train\", \"val\", \"test\"]:\n",
        "        if split == \"train\":\n",
        "            frac = train_frac \n",
        "        elif split == \"val\":\n",
        "            frac = val_frac\n",
        "        else:\n",
        "            frac = test_frac \n",
        "\n",
        "        splits[split] = [indices.pop() for _ in range(int(round(len(dataset) * frac)))]\n",
        "    \n",
        "    return splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7NocE3Tffegn"
      },
      "outputs": [],
      "source": [
        "splits = make_splits(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FlyEVSOWvvxL"
      },
      "outputs": [],
      "source": [
        "loaders = {split: DataLoader(Splitter(dataset, split_dict = splits, split_name = split), batch_size = BATCH_SIZE, drop_last = True, shuffle = True) for split in [\"train\", \"val\", \"test\"]}\n",
        "loaders_no_cwl = {split: DataLoader(Splitter(dataset_no_cwl, split_dict = splits, split_name = split), batch_size = BATCH_SIZE, drop_last = True, shuffle = True) for split in [\"train\", \"val\", \"test\"]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JHdGBFTzB820"
      },
      "outputs": [],
      "source": [
        "from torch import nn, optim, functional\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class ConvNet1D(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(input_channels, 32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.MaxPool1d(5))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv1d(32, 64, kernel_size=3, dilation=2),\n",
        "            nn.ReLU(),\n",
        "            # nn.Dropout(0.5),\n",
        "            nn.MaxPool1d(10))\n",
        "        self.layer3 = nn.Flatten()\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(2496, 512),\n",
        "            nn.Linear(512, 2),\n",
        "            nn.Softmax())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "vxX38hTxPthR"
      },
      "outputs": [],
      "source": [
        "model_conv1d = ConvNet1D(38)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eYJ81fiXw4o3"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def find_last_version(checkpoint_path):\n",
        "    logs_path = checkpoint_path / \"lightning_logs\"\n",
        "    versions = [p for p in logs_path.glob(\"*\") if (p / \"checkpoints\").exists()]\n",
        "    return logs_path / sorted(versions)[-1] if versions != [] else logs_path / \"\"\n",
        "\n",
        "def find_last_checkpoint(checkpoint_path):\n",
        "    checkpoints_path = find_last_version(checkpoint_path) / \"checkpoints\"\n",
        "    print(checkpoints_path)\n",
        "    if list(checkpoints_path.glob(\"*\")) == []:\n",
        "        return None\n",
        "    else:\n",
        "        last_checkpoint = list(checkpoints_path.glob(\"*\"))[0]\n",
        "    return checkpoints_path / last_checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(model, loaders, optimizer, accuracy_json, loss_json, checkpoint_prefix, n_epochs, debug=False, save_every=2):\n",
        "    # Initialize training, validation, test losses and accuracy list\n",
        "\n",
        "    accuracy_json_file_path = Path(accuracy_json)\n",
        "    loss_json_file_path = Path(loss_json)\n",
        "\n",
        "    if accuracy_json_file_path.exists() and accuracy_json_file_path.is_file():\n",
        "        with open(accuracy_json_file_path, \"r+\") as accuracy_json_f:\n",
        "            accuracies_per_epoch = json.load(accuracy_json_f)\n",
        "            print(f\"Loaded accuracy dictionary at {accuracy_json_file_path}\")\n",
        "    else:\n",
        "        accuracies_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "    if loss_json_file_path.exists() and loss_json_file_path.is_file():\n",
        "        with open(loss_json_file_path, \"r+\") as loss_json_f:\n",
        "            losses_per_epoch = json.load(loss_json_f)\n",
        "            print(f\"Loaded loss dictionary at {loss_json_file_path}\")\n",
        "    else:\n",
        "        losses_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "    starting_epoch = 0\n",
        "\n",
        "    checkpoint_path = Path(checkpoint_prefix) \n",
        "\n",
        "    checkpoint_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # Check for the latest weights\n",
        "    checkpoints = [checkpoint.name for checkpoint in checkpoint_path.glob(\"*.pth\") if checkpoint.is_file()]\n",
        "\n",
        "    if len(checkpoints) > 0:\n",
        "        epochs = [int(s.replace(\".pth\", \"\")) for s in checkpoints]\n",
        "\n",
        "        latest_state_dict_path = checkpoint_path / f\"{max(epochs)}.pth\"\n",
        "\n",
        "        # Loading state dict\n",
        "        model.load_state_dict(torch.load(latest_state_dict_path, map_location=DEVICE))\n",
        "        print(f\"Loaded weights generated at epoch {max(epochs)}\")\n",
        "\n",
        "        starting_epoch = max(epochs)\n",
        "\n",
        "    best_accuracy = 0\n",
        "    best_accuracy_val = 0\n",
        "    best_epoch = 0\n",
        "    \n",
        "    predicted_labels = [] \n",
        "    correct_labels = []\n",
        "\n",
        "    print(f\"Training starting at epoch {starting_epoch + 1}\")\n",
        "    for epoch in range(starting_epoch + 1, n_epochs + starting_epoch + 1):\n",
        "        # Initialize loss/accuracy variables\n",
        "        losses = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        accuracies = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        \n",
        "        # Adjust learning rate for SGD\n",
        "        \"\"\"\n",
        "        if OPTIMIZER == \"SGD\":\n",
        "            lr = LEARNING_RATE * (LR_DECAY ** (epoch // LEARNING_RATE_DECAY_EVERY))\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group[\"lr\"] = lr\n",
        "        \"\"\"\n",
        "        \n",
        "        # Process each split\n",
        "        for split in (\"train\", \"val\", \"test\"):\n",
        "            # Set network mode\n",
        "            if split == \"train\":\n",
        "                model.train()\n",
        "                torch.set_grad_enabled(True)\n",
        "            else:\n",
        "                model.eval()\n",
        "                torch.set_grad_enabled(False)\n",
        "            \n",
        "            # Process all split batches\n",
        "            for i, (input, _, target) in enumerate(loaders[split]):\n",
        "\n",
        "                # Move model to device\n",
        "                model = model.to(DEVICE)\n",
        "                \n",
        "                # Move tensors to device\n",
        "                input = input.to(DEVICE)\n",
        "                target = target.to(DEVICE)\n",
        "                \n",
        "                if debug:\n",
        "                    print(input.device)\n",
        "\n",
        "                # Forward\n",
        "                output = model(input.squeeze())\n",
        "\n",
        "                # Compute loss\n",
        "                loss = F.cross_entropy(output, target)\n",
        "                losses[split] += loss.item()\n",
        "                \n",
        "                # Compute accuracy\n",
        "                _, pred = output.data.max(1)\n",
        "                correct = pred.eq(target.data).sum().item()\n",
        "                accuracy = correct / input.data.size(0)   \n",
        "                accuracies[split] += accuracy\n",
        "                counts[split] += 1\n",
        "                \n",
        "                # Backward and optimize\n",
        "                if split == \"train\":\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "        \n",
        "        # Print info at the end of the epoch\n",
        "        if accuracies[\"val\"] / counts[\"val\"] >= best_accuracy_val:\n",
        "            best_accuracy_val = accuracies[\"val\"] / counts[\"val\"]\n",
        "            best_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
        "            best_epoch = epoch\n",
        "\n",
        "        train_loss = losses[\"train\"] / counts[\"train\"]\n",
        "        train_accuracy = accuracies[\"train\"] / counts[\"train\"]\n",
        "        validation_loss = losses[\"val\"] / counts[\"val\"]\n",
        "        validation_accuracy = accuracies[\"val\"] / counts[\"val\"]\n",
        "        test_loss = losses[\"test\"] / counts[\"test\"]\n",
        "        test_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
        "\n",
        "        print(\"INFO\")\n",
        "        print(f\"- Model: {model.__class__.__name__} - epoch {epoch}\")\n",
        "        print(\"STATS\")\n",
        "        print(f\"- Training: Loss {train_loss:.4f}, Accuracy {train_accuracy:.4f} \" \n",
        "            f\"- Validation: Loss {validation_loss:.4f}, Accuracy {validation_accuracy:.4f} \"\n",
        "            f\"- Test: Loss {test_loss:.4f}, Accuracy {test_accuracy:.4f}\")\n",
        "        print(f\"Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = {best_accuracy_val:.4f}) is {best_accuracy:.4f} at epoch {best_epoch}\\n\")\n",
        "\n",
        "        losses_per_epoch[\"train\"].append(train_loss)\n",
        "        losses_per_epoch[\"val\"].append(validation_loss)\n",
        "        losses_per_epoch[\"test\"].append(test_loss)\n",
        "        accuracies_per_epoch[\"train\"].append(train_accuracy)\n",
        "        accuracies_per_epoch[\"val\"].append(validation_accuracy)\n",
        "        accuracies_per_epoch[\"test\"].append(test_accuracy)\n",
        "\n",
        "        if epoch % save_every == 0:\n",
        "            torch.save(model.state_dict(), checkpoint_path / f\"{epoch}.pth\")\n",
        "            \n",
        "            with open(accuracy_json_file_path, \"w+\") as accuracy_json_f:\n",
        "                json.dump(accuracies_per_epoch, accuracy_json_f)\n",
        "            \n",
        "            with open(loss_json_file_path, \"w+\") as loss_json_f:\n",
        "                json.dump(losses_per_epoch, loss_json_f)\n",
        "\n",
        "    # At the end of training, save\n",
        "    torch.save(model.state_dict(), checkpoint_path / f\"{epoch}.pth\")"
      ],
      "metadata": {
        "id": "xRRb4QmZD-fN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv1d_optimizer = torch.optim.Adam(model_conv1d.parameters(), lr=LEARNING_RATE)\n",
        "train_loop(model_conv1d, loaders, conv1d_optimizer, METRICS_PATH / \"conv1d_accuracies.json\", METRICS_PATH / \"conv1d_loss.json\", CHECKPOINT_PATH / \"conv1d_checkpoints\", 52)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R87vgcj6EWsE",
        "outputId": "443c8cd6-4d68-4a01-d9bb-bb56117462a7"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded accuracy dictionary at /content/drive/MyDrive/CWLData/metrics/conv1d_accuracies.json\n",
            "Loaded loss dictionary at /content/drive/MyDrive/CWLData/metrics/conv1d_loss.json\n",
            "Loaded weights generated at epoch 46\n",
            "Training starting at epoch 47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py:204: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO\n",
            "- Model: ConvNet1D - epoch 47\n",
            "STATS\n",
            "- Training: Loss 0.6887, Accuracy 0.5492 - Validation: Loss 0.7057, Accuracy 0.3750 - Test: Loss 0.6866, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.3750) is 0.5833 at epoch 47\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 48\n",
            "STATS\n",
            "- Training: Loss 0.6878, Accuracy 0.5530 - Validation: Loss 0.7055, Accuracy 0.3750 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.3750) is 0.5417 at epoch 48\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 49\n",
            "STATS\n",
            "- Training: Loss 0.6879, Accuracy 0.5530 - Validation: Loss 0.7017, Accuracy 0.3958 - Test: Loss 0.6892, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.3958) is 0.5625 at epoch 49\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 50\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7023, Accuracy 0.4167 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5208 at epoch 50\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 51\n",
            "STATS\n",
            "- Training: Loss 0.6875, Accuracy 0.5540 - Validation: Loss 0.7071, Accuracy 0.3542 - Test: Loss 0.6905, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5208 at epoch 50\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 52\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5502 - Validation: Loss 0.7018, Accuracy 0.4167 - Test: Loss 0.6942, Accuracy 0.5000\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 52\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 53\n",
            "STATS\n",
            "- Training: Loss 0.6889, Accuracy 0.5502 - Validation: Loss 0.7016, Accuracy 0.4167 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 54\n",
            "STATS\n",
            "- Training: Loss 0.6878, Accuracy 0.5530 - Validation: Loss 0.7101, Accuracy 0.3333 - Test: Loss 0.6903, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 55\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5511 - Validation: Loss 0.7038, Accuracy 0.3958 - Test: Loss 0.6885, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 56\n",
            "STATS\n",
            "- Training: Loss 0.6886, Accuracy 0.5502 - Validation: Loss 0.7029, Accuracy 0.3958 - Test: Loss 0.6905, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 57\n",
            "STATS\n",
            "- Training: Loss 0.6886, Accuracy 0.5502 - Validation: Loss 0.7069, Accuracy 0.3750 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 53\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 58\n",
            "STATS\n",
            "- Training: Loss 0.6875, Accuracy 0.5540 - Validation: Loss 0.7023, Accuracy 0.4167 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5625 at epoch 58\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 59\n",
            "STATS\n",
            "- Training: Loss 0.6883, Accuracy 0.5511 - Validation: Loss 0.7037, Accuracy 0.3958 - Test: Loss 0.6942, Accuracy 0.5000\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5625 at epoch 58\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 60\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7015, Accuracy 0.4167 - Test: Loss 0.6868, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5833 at epoch 60\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 61\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5530 - Validation: Loss 0.7059, Accuracy 0.3750 - Test: Loss 0.6865, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5833 at epoch 60\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 62\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.7020, Accuracy 0.4167 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 62\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 63\n",
            "STATS\n",
            "- Training: Loss 0.6877, Accuracy 0.5530 - Validation: Loss 0.7043, Accuracy 0.3958 - Test: Loss 0.6903, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 62\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 64\n",
            "STATS\n",
            "- Training: Loss 0.6884, Accuracy 0.5502 - Validation: Loss 0.7094, Accuracy 0.3333 - Test: Loss 0.6961, Accuracy 0.4792\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5417 at epoch 62\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 65\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.7015, Accuracy 0.4167 - Test: Loss 0.6941, Accuracy 0.5000\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 66\n",
            "STATS\n",
            "- Training: Loss 0.6876, Accuracy 0.5540 - Validation: Loss 0.7030, Accuracy 0.3958 - Test: Loss 0.6869, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 67\n",
            "STATS\n",
            "- Training: Loss 0.6885, Accuracy 0.5511 - Validation: Loss 0.7115, Accuracy 0.3333 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 68\n",
            "STATS\n",
            "- Training: Loss 0.6877, Accuracy 0.5540 - Validation: Loss 0.7043, Accuracy 0.3958 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 69\n",
            "STATS\n",
            "- Training: Loss 0.6879, Accuracy 0.5530 - Validation: Loss 0.7041, Accuracy 0.3958 - Test: Loss 0.6903, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 70\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5521 - Validation: Loss 0.7030, Accuracy 0.3958 - Test: Loss 0.6905, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 71\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5521 - Validation: Loss 0.7088, Accuracy 0.3542 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4167) is 0.5000 at epoch 65\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 72\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.6978, Accuracy 0.4583 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 73\n",
            "STATS\n",
            "- Training: Loss 0.6883, Accuracy 0.5511 - Validation: Loss 0.7064, Accuracy 0.3542 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 74\n",
            "STATS\n",
            "- Training: Loss 0.6883, Accuracy 0.5511 - Validation: Loss 0.7082, Accuracy 0.3542 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 75\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5502 - Validation: Loss 0.7017, Accuracy 0.4167 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 76\n",
            "STATS\n",
            "- Training: Loss 0.6886, Accuracy 0.5483 - Validation: Loss 0.7052, Accuracy 0.3750 - Test: Loss 0.6867, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 77\n",
            "STATS\n",
            "- Training: Loss 0.6884, Accuracy 0.5502 - Validation: Loss 0.7079, Accuracy 0.3542 - Test: Loss 0.6884, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 78\n",
            "STATS\n",
            "- Training: Loss 0.6887, Accuracy 0.5492 - Validation: Loss 0.7064, Accuracy 0.3750 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 79\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7047, Accuracy 0.3750 - Test: Loss 0.6905, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 80\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5521 - Validation: Loss 0.7069, Accuracy 0.3750 - Test: Loss 0.6986, Accuracy 0.4583\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 81\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7028, Accuracy 0.3958 - Test: Loss 0.6958, Accuracy 0.4792\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 82\n",
            "STATS\n",
            "- Training: Loss 0.6884, Accuracy 0.5502 - Validation: Loss 0.7019, Accuracy 0.4167 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 83\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7042, Accuracy 0.3958 - Test: Loss 0.6903, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 84\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5511 - Validation: Loss 0.7077, Accuracy 0.3542 - Test: Loss 0.6885, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 85\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5521 - Validation: Loss 0.7022, Accuracy 0.4167 - Test: Loss 0.6844, Accuracy 0.6042\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 86\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.7055, Accuracy 0.3750 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 87\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5521 - Validation: Loss 0.7090, Accuracy 0.3333 - Test: Loss 0.6886, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 88\n",
            "STATS\n",
            "- Training: Loss 0.6885, Accuracy 0.5502 - Validation: Loss 0.7077, Accuracy 0.3542 - Test: Loss 0.6904, Accuracy 0.5417\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 89\n",
            "STATS\n",
            "- Training: Loss 0.6880, Accuracy 0.5511 - Validation: Loss 0.7016, Accuracy 0.4167 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 90\n",
            "STATS\n",
            "- Training: Loss 0.6881, Accuracy 0.5511 - Validation: Loss 0.7023, Accuracy 0.4167 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 91\n",
            "STATS\n",
            "- Training: Loss 0.6885, Accuracy 0.5502 - Validation: Loss 0.7041, Accuracy 0.3958 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 92\n",
            "STATS\n",
            "- Training: Loss 0.6882, Accuracy 0.5511 - Validation: Loss 0.7029, Accuracy 0.3958 - Test: Loss 0.6887, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 93\n",
            "STATS\n",
            "- Training: Loss 0.6877, Accuracy 0.5540 - Validation: Loss 0.7018, Accuracy 0.4167 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 94\n",
            "STATS\n",
            "- Training: Loss 0.6879, Accuracy 0.5521 - Validation: Loss 0.7058, Accuracy 0.3750 - Test: Loss 0.6923, Accuracy 0.5208\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 95\n",
            "STATS\n",
            "- Training: Loss 0.6879, Accuracy 0.5521 - Validation: Loss 0.7054, Accuracy 0.3750 - Test: Loss 0.6885, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 96\n",
            "STATS\n",
            "- Training: Loss 0.6884, Accuracy 0.5492 - Validation: Loss 0.7022, Accuracy 0.4167 - Test: Loss 0.6883, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 97\n",
            "STATS\n",
            "- Training: Loss 0.6876, Accuracy 0.5540 - Validation: Loss 0.7069, Accuracy 0.3750 - Test: Loss 0.6881, Accuracy 0.5625\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n",
            "INFO\n",
            "- Model: ConvNet1D - epoch 98\n",
            "STATS\n",
            "- Training: Loss 0.6876, Accuracy 0.5530 - Validation: Loss 0.7017, Accuracy 0.4167 - Test: Loss 0.6866, Accuracy 0.5833\n",
            "Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = 0.4583) is 0.5208 at epoch 72\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv1d_no_cwl = ConvNet1D(32)\n",
        "conv1d_no_cwl_optimizer = torch.optim.Adam(model_conv1d_no_cwl.parameters(), lr=LEARNING_RATE)\n",
        "train_loop(model_conv1d_no_cwl, loaders_no_cwl, conv1d_no_cwl_optimizer, METRICS_PATH / \"conv1d_no_cwl_accuracies.json\", METRICS_PATH / \"conv1d_no_cwl_loss.json\", CHECKPOINT_PATH / \"conv1d_no_cwl_checkpoints\", 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "AckwvVkCKPIs",
        "outputId": "bb1c9e21-1458-410a-f2ba-29325314fbcd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fc502fb2fd29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_conv1d_no_cwl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mconv1d_no_cwl_optimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv1d_no_cwl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_conv1d_no_cwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloaders_no_cwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv1d_no_cwl_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETRICS_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"conv1d_no_cwl_accuracies.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMETRICS_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"conv1d_no_cwl_loss.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCHECKPOINT_PATH\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"conv1d_no_cwl_checkpoints\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ConvNet1D' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet3D(nn.Module):\n",
        "    def __init__(self, input_channels):\n",
        "        super().__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv3d(input_channels, 32, kernel_size=3),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.MaxPool1d(5))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv3d(32, 64, kernel_size=3, dilation=2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.MaxPool1d(10))\n",
        "        self.layer3 = nn.Flatten()\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Linear(2496,2),\n",
        "            nn.Softmax())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "C5UYnywgKSOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop_fmri(model, loaders, optimizer, accuracy_json, loss_json, checkpoint_prefix, n_epochs, debug=False, save_every=2):\n",
        "    # Initialize training, validation, test losses and accuracy list\n",
        "\n",
        "    accuracy_json_file_path = Path(accuracy_json)\n",
        "    loss_json_file_path = Path(loss_json)\n",
        "\n",
        "    if accuracy_json_file_path.exists() and accuracy_json_file_path.is_file():\n",
        "        with open(accuracy_json_file_path, \"r+\") as accuracy_json_f:\n",
        "            accuracies_per_epoch = json.load(accuracy_json_f)\n",
        "            print(f\"Loaded accuracy dictionary at {accuracy_json_file_path}\")\n",
        "    else:\n",
        "        accuracies_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "    if loss_json_file_path.exists() and loss_json_file_path.is_file():\n",
        "        with open(loss_json_file_path, \"r+\") as loss_json_f:\n",
        "            losses_per_epoch = json.load(loss_json_f)\n",
        "            print(f\"Loaded loss dictionary at {loss_json_file_path}\")\n",
        "    else:\n",
        "        losses_per_epoch = {\"train\": [], \"val\": [], \"test\": []}\n",
        "\n",
        "    starting_epoch = 0\n",
        "\n",
        "    checkpoint_path = Path(checkpoint_prefix) \n",
        "\n",
        "    checkpoint_path.mkdir(exist_ok=True)\n",
        "\n",
        "    # Check for the latest weights\n",
        "    checkpoints = [checkpoint.name for checkpoint in checkpoint_path.glob(\"*.pth\") if checkpoint.is_file()]\n",
        "\n",
        "    if len(checkpoints) > 0:\n",
        "        epochs = [int(s.replace(\".pth\", \"\")) for s in checkpoints]\n",
        "\n",
        "        latest_state_dict_path = checkpoint_path / f\"{max(epochs)}.pth\"\n",
        "\n",
        "        # Loading state dict\n",
        "        model.load_state_dict(torch.load(latest_state_dict_path, map_location=DEVICE))\n",
        "        print(f\"Loaded weights generated at epoch {max(epochs)}\")\n",
        "\n",
        "        starting_epoch = max(epochs)\n",
        "\n",
        "    best_accuracy = 0\n",
        "    best_accuracy_val = 0\n",
        "    best_epoch = 0\n",
        "    \n",
        "    predicted_labels = [] \n",
        "    correct_labels = []\n",
        "\n",
        "    print(f\"Training starting at epoch {starting_epoch + 1}\")\n",
        "    for epoch in range(starting_epoch + 1, n_epochs + starting_epoch + 1):\n",
        "        # Initialize loss/accuracy variables\n",
        "        losses = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        accuracies = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        counts = {\"train\": 0, \"val\": 0, \"test\": 0}\n",
        "        \n",
        "        # Adjust learning rate for SGD\n",
        "        \"\"\"\n",
        "        if OPTIMIZER == \"SGD\":\n",
        "            lr = LEARNING_RATE * (LR_DECAY ** (epoch // LEARNING_RATE_DECAY_EVERY))\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group[\"lr\"] = lr\n",
        "        \"\"\"\n",
        "        \n",
        "        # Process each split\n",
        "        for split in (\"train\", \"val\", \"test\"):\n",
        "            # Set network mode\n",
        "            if split == \"train\":\n",
        "                model.train()\n",
        "                torch.set_grad_enabled(True)\n",
        "            else:\n",
        "                model.eval()\n",
        "                torch.set_grad_enabled(False)\n",
        "            \n",
        "            # Process all split batches\n",
        "            for i, (_, input, target) in enumerate(loaders[split]):\n",
        "\n",
        "                # Move model to device\n",
        "                model = model.to(DEVICE)\n",
        "                \n",
        "                # Move tensors to device\n",
        "                input = input.to(DEVICE)\n",
        "                target = target.to(DEVICE)\n",
        "                \n",
        "                if debug:\n",
        "                    print(input.device)\n",
        "\n",
        "                # Forward\n",
        "                output = model(input.squeeze())\n",
        "\n",
        "                # Compute loss\n",
        "                loss = F.cross_entropy(output, target)\n",
        "                losses[split] += loss.item()\n",
        "                \n",
        "                # Compute accuracy\n",
        "                _, pred = output.data.max(1)\n",
        "                correct = pred.eq(target.data).sum().item()\n",
        "                accuracy = correct / input.data.size(0)   \n",
        "                accuracies[split] += accuracy\n",
        "                counts[split] += 1\n",
        "                \n",
        "                # Backward and optimize\n",
        "                if split == \"train\":\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "        \n",
        "        # Print info at the end of the epoch\n",
        "        if accuracies[\"val\"] / counts[\"val\"] >= best_accuracy_val:\n",
        "            best_accuracy_val = accuracies[\"val\"] / counts[\"val\"]\n",
        "            best_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
        "            best_epoch = epoch\n",
        "\n",
        "        train_loss = losses[\"train\"] / counts[\"train\"]\n",
        "        train_accuracy = accuracies[\"train\"] / counts[\"train\"]\n",
        "        validation_loss = losses[\"val\"] / counts[\"val\"]\n",
        "        validation_accuracy = accuracies[\"val\"] / counts[\"val\"]\n",
        "        test_loss = losses[\"test\"] / counts[\"test\"]\n",
        "        test_accuracy = accuracies[\"test\"] / counts[\"test\"]\n",
        "\n",
        "        print(\"INFO\")\n",
        "        print(f\"- Model: {model.__class__.__name__}\")\n",
        "        print(\"STATS\")\n",
        "        print(f\"- Training: Loss {train_loss:.4f}, Accuracy {train_accuracy:.4f} \" \n",
        "            f\"- Validation: Loss {validation_loss:.4f}, Accuracy {validation_accuracy:.4f} \"\n",
        "            f\"- Test: Loss {test_loss:.4f}, Accuracy {test_accuracy:.4f}\")\n",
        "        print(f\"Best Test Accuracy at maximum Validation Accuracy (validation_accuracy = {best_accuracy_val:.4f}) is {best_accuracy:.4f} at epoch {best_epoch}\\n\")\n",
        "\n",
        "        losses_per_epoch[\"train\"].append(train_loss)\n",
        "        losses_per_epoch[\"val\"].append(validation_loss)\n",
        "        losses_per_epoch[\"test\"].append(test_loss)\n",
        "        accuracies_per_epoch[\"train\"].append(train_accuracy)\n",
        "        accuracies_per_epoch[\"val\"].append(validation_accuracy)\n",
        "        accuracies_per_epoch[\"test\"].append(test_accuracy)\n",
        "\n",
        "        if epoch % save_every == 0:\n",
        "            torch.save(model.state_dict(), checkpoint_path / f\"{epoch}.pth\")\n",
        "            \n",
        "            with open(accuracy_json_file_path, \"w+\") as accuracy_json_f:\n",
        "                json.dump(accuracies_per_epoch, accuracy_json_f)\n",
        "            \n",
        "            with open(loss_json_file_path, \"w+\") as loss_json_f:\n",
        "                json.dump(losses_per_epoch, loss_json_f)\n",
        "\n",
        "    # At the end of training, save\n",
        "    torch.save(model.state_dict(), checkpoint_path / f\"{epoch}.pth\")"
      ],
      "metadata": {
        "id": "2KrqCMH1WR6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv3d = ConvNet3D(1)\n",
        "conv3d_optimizer = torch.optim.Adam(model_conv3d.parameters(), lr=LEARNING_RATE)\n",
        "train_loop_fmri(model_conv3d, loaders, conv3d_optimizer, METRICS_PATH / \"conv3d_accuracies.json\", METRICS_PATH / \"conv3d_loss.json\", CHECKPOINT_PATH / \"conv3d_checkpoints\", 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yxCphOeUIgCe",
        "outputId": "4fbb4d64-6090-4051-d45c-9bfb9905d3d8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ConvNet1D'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "095fuS9UQBCE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyPy0CAMvCsVa5T9CapVtXZT",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}